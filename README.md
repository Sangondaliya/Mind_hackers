# Mind_hackers
DAIICT Hackathon DCEI 3/2/23 - 5/2/23

# The problem Statement:
Designing a tool that uses computer vision to provide real-time captioning and translation
for students with hearing or language impairments or any other physical disabilities.

# Proposed Solution
We propose a solution which will provide for people that are blind and visually impaired and deaf with hearing impairment. We will use tools like openCV, MediaPipe and Tensorflow for computer vision where we can provide video files as input and recognize the audio/content by using lip recognition using Dlib (proposed) and Gesture Recognition to understand Sign Language which will convert it using AV-ASR and translate it to text/caption for deaf students. We are also providing login into the app as audio for blind people. Blind people can also input instructions using their speech to operate their computer.

# Back Study
Important statistics to consider:
1. There are a total of 36 Million people that are blind and 217 million with visually impairment across the world.
2. Prevalence of visually impaired: 4.58% in 1990 v/s 3.38% in 2015
3. 55% of visually impaired people are women.
4. 89% of visually impaired people live in low & middle income countries.
5. China and India Contribute 49% of the total population of blindness and vision impairment.
6. 70% of adults who are blind are unemployed.
7. 50% of High School students who are blind dropout before graduating.
8. It is estimated 1:3 people who have a disability between the ages of 18 and 64 live in poverty.
9. 65% of people were not living in pverty prior to their disability

Over the years, studies conducted on development of children and education, sociology, physiology and special education have resulted in advancement of their growth and achieve greater self-esteem and social fulfilment and acceptance by personal nurturing in the least restrictive environment and them being involved in their community. 
	The objectives of integrated education:
1.	Provide the same opportunities and experiences for blind or visually impaired children as that of sighted children.
2.	Allow blind children – and their families, neighbours, and friends – to interact socially.
Integrated education is not simply placing a child in a regular classroom. The children can assimilate more than 80% of the teaching in the class if they are provided with the correct material in the correct form at the correct time. 

Closed captions were originally developed to help the hearing impaired. Language learners performed significantly better in objective vocabulary testing when they watched videos with closed captions compared to when they did not watch videos without closed captions. 



![image](https://user-images.githubusercontent.com/123167152/216749844-a5c057a8-cced-4aae-a5c1-52bd0e806a7c.png)






References:
1. https://www.jstor.org/stable/26234914
2. https://brailleworks.com/braille-literacy-statistics/
3. https://www.kaggle.com/datasets/innominate817/hagrid-sample-30k-384p
4. https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/python
5. https://techvidvan.com/tutorials/hand-gesture-recognition-tensorflow-opencv/
6. https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/python
7. https://pypi.python.org/packages/da/06/bd3e241c4eb0a662914b3b4875fc52dd176a9db0d4a2c915ac2ad8800e9e/dlib-19.7.0-cp36-cp36m-win_amd64.whl#md5=b7330a5b2d46420343fbed5df69e6a3f
8. https://crownschool.uchicago.edu/ssa_magazine/sign-language-best-deaf-children.html
9. hassanhub/LipReading
10. LipReading/demo at master · hassanhub/LipReading
11. LipReading/demo/autoencoder (targets to network) at master · hassanhub/LipReading
12. LipReading/demo/autoencoder (targets to network)/coded_decoded at master · hassanhub/LipReading
13. LipReading/codes at master · hassanhub/LipReading
14. deep_lip_reading/requirements.txt at master · afourast/deep_lip_reading
15. nicknochnack/LipNet
